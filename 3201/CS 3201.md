

#  CS 3201 Note

--------

## Tutorial 1

-------

### 1. Some devices

* Network Interface card : Connects computers to a network using cables. Any device needs a network interface card to connect to the internet
* Network cables : Network cables have connectors on each end that plug into network interface cards
* Cable modern(路由器) : connets your home computer or wireless router to your *Internet Service Provider* (ISP 中国移动) 
* Bluetooth headsets : When Bluetooth is switched on, you device will search for other Bluetooth device to connect to main ebabler if (PAN)
* WIFI router : allow share of internet connection main enabler of (LAN)
* Fare for each device connected to it
  * Hubs : allow devices to connect to each other by plugging network cables into their ports
  * Switch : works similar to hubs, but it can recongonize data (not anyone can access it)
* Router : Allows computers on a LAN to share the same Internet connection
* Bridge: Used to connect multiple LANs together
* Cellular Network Base station: e.g. a 4G station
* A router in the *core network* or wide area network(WAN)

--------------

## Lecture 1

-------

## 1. 1 What is Internet

----------

### 1.1.1 A Nuts-and-Bolts Description

* millions of connected computing devices: *hosts = end systems*
  * running *network apps*
* communication links
  * Fiber, copper, radio, satellite (physical media)
  * transmission **rate** = bandwidth (bits/seconds)
* Packets = header(add by the sender) + segment of file
  * packet switch: receive packets and forward packets toward their ultimate destinations
    * Link-layer switches : used in access networks
    * Routers: forward packets (chunks of data) (packets: divide big file into small units called packets) used in network cores
* Internet: "network of networks"
  * loosely hierarchical (树) => all connected together
  * public Internet versus private intranet
* ISPs : Internet service provider => provide internet-access service to end systems
  - Tier1: national
  - Tier2: regional => connect 1 or more Tier1
  - Tier3: ISPs and local ISPs => closest to end systems
* Protocols controls sending, receiving of msgs
  * e.g. TCP, IP, HTTP, Skype, Ethernet
  * Protocols define **format, order** of msgs sent and received among network entities, and **actions ** taken on msg transmission and receiption  
  * Internet standards
    * RFC: Request for comments
    * IETF: Internet Engineering Task Force

### 1.1.2 A Services Description

* Distributed applications: Applications involve multiple end systems that exchange data with each other, and run a the end systems.

* Service

  * communication *infrastructure* (and delivery system i.e. protocols) enables distributed applications
    * Web, VoIP, email, games, e-commerce, file sharing
  * communication services provided to apps:
    * Reliable data delivery from source to destination
    * "Best effort" (unreliable) data delivery => some times we prefer loss of bits than speed of transformation(online game/movie)

--------------

## 1.2 The network edge

-------------

### 1.2.1 Access Networks

* network edge: applications and hosts 
* Hosts / end systems
  * client
  * server
* access networks(edge router): the network that physically connects an end system to the **first** router 
  * e.g.
    * DSL (digital subscriber line) : A residence typically obtains DSL Internet access from the same local telephone company (telco) that provides its wired local phone access.  
    * Cable, FTTH, Dial-Up and Satellite
  * Properties
    * slower than core
    * dedicated(私有)

----------

### 1.3 The Network Core

#### 1.3.1 Packet switching

* Store-and-Forward Transmission :packet switch must receive the entire packet before it can begin to transmit the first bit of the packet onto the outbound link 
  * Consider : source has three packets, each consist of L bits
  * First buffer the packet's bits : size of packets is L, rate is R
  * transmission(for one packet) delay = (L/R)*number of links
* Queuing Delays and Packet Loss
  * For each link linked to the **output buffer**(output queue)
  * Store the packets to the queue when the output link is busy
  * The queue has finity capacity
  * packet arriving to full queue dropped (aka lost)
  * lost packet may be retransmitted by previous node, by source end system, or not at all
* Forwarding Tables and Routing Protocols
  * IP address of target host is writen in the header of packets by the sender host
  * Forwarding table: Each router has an forward table that maps destination addresses
  * Packets' IP is read by the table to find appropriate outbound link

#### 1.3.2 Circuit Switching

* circuit-switched network : set up a new path between sourse and target

  - dedicated resources: no sharing

  -  circuit-like (guaranteed) performance

  - call setup required

  - dividing link bandwidth into “pieces”

    - frequency-division multiplexing : share channel

      - FM radio stations also use FDM to share the frequency spectrum between 88 MHz and 108 MHz, with each station being allocated a specific frequency band. 

    - Time-division multiplexing(TDM): use whole channel but share on time

      - Frame: time is divided into frames of fixed duration 
      - Slots: each frame is divided into a fixed number of time slots
      - When the network establishes a connection across a link, the network dedicates one time slot in every frame to this connection 
      - transmission rate of a circuit is equal to the frame rate multiplied by the number of bits in a slot (frame per second*number of bits in a slot = slot per second/slot per frame * number of bits)
      - Bit rate: total bits per second
      - transmission rate: for one slot (bit rate/slots per sec)

      $$
      dely\ time=time\ to\ set\ up+{packet\ size\over( {bit\ rate\over slots\ per\ sec})}(total\ slots)
      $$

* Packet Switching Versus Circuit Switching

  * packet-switching: data sent thru net in discrete “chunks” （router决定下一个方向， if busy store into buffer）
    * A, B packets share $\color{red}{network}$ resources
    * each packet uses full link bandwidth
    * resource contention
      * aggregate resource demand can exceed amount available
      * congestion: packets queue, wait for link use
      * store and forward: packets move one hop at a time
      * Node receives complete packet before forwarding
  * Statistical multiplexing
    - Sequence of A & B packets does not have fixed pattern, bandwidth shared on demand => statistical multiplexing
    - each host gets same slot in revolving TDM frame
  * transmit delay : (num of edges*size of file)/deliver rate
  * packet switching > circuit switching
    - Great for bursty(Discrete) data
      - resource sharing
      - Simpler, no call setup
    - excessive congestion: packet delay and loss
      - protocols needed for reliable data transfer, congestion control
    - How to provide circuit-like behaviour
      - bandwidth guarantees needed for audio/video apps (pay for the service)

* network core: 
  * interconnected **routers**
  * network of networks

### 1.4 Delay, Loss, and Throughput in Packet-Switched Networks

* Four sources of delay

  - Nodal processing : check bit errors and determine output link （negligible 可忽略）

  - Queueing : time waiting at output for transmission and depends on congestion level of router  (not negligible)

  - Transmission delay : L(file size)/R(rate) (negligible)

  - Propagation delay : down voteaccepted (negligible)

    Propagation delay is how long it takes *one* bit to *travel* from one end of the "wire" to the other (it's proportional to the length of the wire, crudely).

    Transmission delay is how long it takes to get *all* the bits *into* the wire in the first place (it's packet_length/data_rate).
    $$
    d_{nodal}=d_{proc}+d_{queue}+d_{trans}+d_{pop} 
    $$

  - Throughput

    - Throughput: rate(bits/time unit) at which bits transfeered between sender/receiver (observe from receiver side)
      - Instantaneous : At any instant of time is the rate(bits/sec) at which Host B is receiving the file
      - Average : 平均速度 F(whole bits)/T(whole time)
      - Consider $R_S$ is the rate of link between server and router $R_c$ denote the rate of the link between client and router, then the transmission rate is min($R_S$,$R_c$)
      - Per-connection end-end throughput: min($R_S$,$,R_c$, R/10)
      - in practice: $R_S$ and $R_c$ is oftehn bottleneck

  ### 1.5 Protocol Layers and Their Service Models

  * Layer : each layer implements a service

    * via its own internal-layer actions
    * relying on services provided by layer below (down to top)
    * advantage: different implement of layer(layer's function has not changed) doesn't affect the whole system's function

  * Protocol Layering

    * To provide structure to the design of network protocols, network designers organize protocols-and the network harware and software

  * Internet protocol stack : Protocols of the various layers are called the protocol stack

    * Application Layer : supporting network applications
      * functions : Such as the translation of human-friendly names for Internet end systems to a 32-bit network address
      * FTP, SMTP, HTTP
      * **Message** : The application in one end system using the protocol to exchange packets of information with the application in another end system, the packet of information **at application layer** is message
    * Transport Layer : processing data and transfer
      * Transports application-layer messages between application endpoints.
      * May used to
        * deliver the message up to the appropriate application
        * Error-detection bits that allow the receiver to determine whether bits in the message has changed in the route
      * TCP, UDP
        * TCP: provides a connection-oriented service to its applications
          * guaranteed delivery of application-layer messages to the destination and flow control(sender/receiver speed matching)
        * UDP: provides a connectionless service to its applications
      * **Segment**: We will refer to a transport-layer packet as segment
    * Network Layer : routing of datagrams from source to destination (for router decide output link)
      * Responsible for moving network-layer packets known as **datagrams** from one host to another
      * Internet transport-layer protocol(TCP/UDP) in a source host passes a transport-layer segment and a destination address to the network layer
      * The network layer provides the service of delivering the segment to the transport layer in the destination host
      * IP, routing protocols
        * IP : Defines the fields in the datagram as well as how the end systems and routers act on these fields (only one IP protocol, and all Internet component has a network layer must run the IP protocol)
        * Rooting protocol : determine the routes that datagrams take between sources and destinations
    * Link Layer: data transfer between neighboring network elements (avoid collision, generate different number)
      * Packets called **Link-layer frame** (has two kinds of fields)
        * header fields 
        * **payload field**:Typicaly from layer above
      * To move a packet from one node (host or router) to the next node in the route
      * Service provided depends on the link-layer protocol that is employed over the link
      * PPP, Ethernet
    * Physical : bits "on the wire" (from bits to signal)

  * ISO/OSI reference model (2 layers between application and transport) => do have this in the history

    * presentation : allow applications to interpret meaning of data (encryption, compression, machine-specific conventions)
    * Session : synchoronization, checkpointing, recovery of data exchange

    ![](layer.png)

  * The graph of layers

    * Only destination delete header, only source add header , only this two have 5 layers
    * switch only has 2 layers(do not know IP protocol), routers only have 3 layers
    * Host(end systems) implement all five layers, (Internet architecture puts much of its complexity at the edge of the network(网络的最边缘， 不是图论中的edge))

  * Encapsulation

    * Sending host: An **application-layer message** is passed to the transport layer

    * Transport layer: Take the messages and appends additional information(*Transport-layer header*) that will be used by teh receiver-side transport layer
      $$
      (application-layer\ information)+(transport-layer\ header)=(transport-layer\ segment)
      $$

    * Network Layer: Then every layer add its header

---------------

## Tutorial 2

|                         | Circuit Switching | Packet Switching                                             |
| ----------------------- | ----------------- | ------------------------------------------------------------ |
| Resource Usage          | Reservation       | Share the resources                                          |
| Performance             | stable            | Unpredictable (congestion may happen) (delay and loss)       |
| Set up                  | Needed            | Not needed                                                   |
| Multiplexing (多路传输) | TDM/FDM           | Divide the whole file into packets => statistical multiplexing |



* For long-term steady rate transmission Circuit switching  is better

* Skype offers a function to have phone call between computers and phones (connect computer network with telephone network) How?

   Skype app $\Leftarrow$ Packet switching (Internet (packets))$\Rightarrow$ Gateway $\Leftarrow$ Circuit switching(Telephone net (stream)) $\Rightarrow$ Phone

* How long does it take a packet of length 2000 bytes to ==propagate== over a link of distance 2000 km, propagation speed $2*10^8 m/s$, and transmission rate 2Mbps(it is **bits**)?

  * Transmission delay : time spend for **push data to link**

  * Propogation delay : time spend **on the link**
    $$
    td = {L\over R} = {2000*8\over 2*10^6} = 0.008s
    $$

    $$
    pd={2*10^6\over 2*10^8}=0.01s
    $$

* Suppose that users share a 10Mbps link, i.e., they all send traffic to a node which has a 10Mbps link to forward the traffic received from the users. Suppose that each user transmits continuously at 5Mbps when transmitting, but each user transmits only 20% of the time.  

  * When circuit switching is used, how many users can be supported? => 2

  * Suppose that there are **4** users and packet switching is used. What is the fraction of time that the queue at the node is not empty? 
    $$
    p=C_4^3*0.2^3*0.8+C_4^4*0.2^4
    $$


----------------

## Chapter 2

----------

### 2.1 Principles of Network Applications

* creating an internet app

  * program on different ending systems(all end systems can use it)

* Application architecher

  * p2p (pear to pear)
  * Client - Server
    * Server
      * always on host
      * permanent IP address (not local IP address)
      * data centers for scaling
    * Client
      * call communication first
      * may be intermittently(间隔) connected
      * may have dynamic IP addresses
      * do not communicate directly with each other
    * Data center:
      * Single server can't response to all the requests
      * data center housing a large number of hosts, often used to vreate a powerful virtual server

* P2P

  * no always-on server (everyone service each other)
  * arbitary ending systems directly connected
  * No or minimal reliance on dedicated server
  * peers are intermittently connected and change IP addresses
    * complex management
  * Feature : **self-scalability**

* Process communicating

  * Process : program running within a host (ending systems)
    * with the same host, two processed using $\color {red}{interprocess\ communcation}$ (defined by *OS*)
    * processes in different hosts communicate by exchanging messages
    * Include client process(initialize communication) and server process

* **Interface between the process and the computer network**

  ![](API.png)

  * A process sends messages into or receives messages from the network through a software interface called **socket** (also called **API** between applications and network) (multiplication)
  * Control by the application developer
    * (1) the choice of transport protocol and 
    * (2) perhaps the ability to fix a few transport-layer parameters such as maximum buffer and maximum segment sizes (to be covered in Chapter 3). 
  * Address processes : for client to match message returned and process or server to match process and coming message
    * Unique IP address for identifying client
    * *identifiers* includes both **IP address** and **port numbers**

#### 2.1.3 Transport Services Available to Applications

* On the receiver side, transport layer send the message to the application layer (demultiplexing)

* Transport-layer protocols is determined by the application layer needs

  * Reliable data transfer

    * To transfer data that affected a lot by loss of bits (e-mail, file transfer, remote host access, financial applications)
    * e.g. process-to-process reliable data transfer (otherwise, **loss-tolerant applications**)

  * Throughput

    * Other sessions are sharing bandwidth with current task, the avaliable throughput can fluctuate with time
    * Another natural service : Guaranteed available throughput at some specified rate => **bandwidth-sensitive applications** (otherwise, **elastic applcations**)

  * Timing

  * Security

    ![](ReqSer.png)

### 2.1.4 Transport Services Provided by the Internet

* TCP services
  * Connection-oriented service
    * TCP has the client and server exchange transport-layer control information with each other *before* the application-level messages => hand shaking
    * TCP connection is between the sockets of the two processes can send messages to each other over the connection at the same time
  * reliable data transfer service
    * Deliver all data sent without error and in the proper order
    * When one side of the application passes a stream of bytes into a socket, it can count on TCP to deliver the same stream of bytes to receiving socket
  * Congestion-control mechanism(抗阻塞机制)
    * For the welfare of the whole Internet rather than for the direct benefit of the communicating processes
* UDP services
  - UDP is a no-frills(没多余装饰) lightweight transport protocol => no hand shaking, unreliable transfer, data may out of order, no congestion-control mechanism

### 2.1.5 Application-Layer Protocols

* Application-layer protocol define how an application's processes, running on different end systems, pass messages to each other. It defines:
  * The type of messages exchanged, for example, request messages and response messages
  * The syntax of the various message types, such as the fields in the message and how the fields are delineated(划定) 
  * The semantics of the fields, that is, the meaning of the information in the fields
  * Rules for determining when and hows a process sends messages and responds to the message

* types of messages exchanged, 
  * e.g., request, response 
  * message syntax:
    *  what fields in messages & how fields are delineated
  * message semantics 
    * meaning of information in fields
  * rules for when and how processes send & respond to messages
    * HTTP, DNS，Skype 

### 2.2 The Web and HTTP

* unlike traditional broadcast radio and TV, users receive what they want, when they want it => force user to tune in when the content provider makes the content available

### 2.2.1 Overview of HTTP

* Web overview
  * Web and HTTP
    * web page consist of referenced objects which are based on *HTML* file
    * Each object is addressed by a URL (Every objects has its URL refered by HTML)
  * HTTP: Web's ==application layer== protocol => **HyperText Transfer Protocol** implementing 2 programs
    * Client program : browser (using HTTP protocol and "displays" web objects)
    * server program: Web server sends (using HTTP protocol) objects in response to requests 
    * HTTP based on TCP : 
      * client initiates connection

        * client sends HTTP request messages into its socket interface and receives HTTP response messages from its socket interface
        * When message sent into its socket interface, it is out of hand of HTTP or client's hand, it is in control of TCP => HTTP don't have to warry about how data loss is recovered or bits are reordered, because that is job of TCP(like OOP) => advantage of layered architecture

      * Server accepts TCP connection from client

        * Server sends requested files to clients without storing any state information about the client

          => if a client ask for the same object twice, server will do it => HTTP is **stateless protocol**

      * HTTP messages (application-layer protocol messages) exchanged between browser (HTTP client) and Web server (HTTP server)

      * TCP connection is closed

  ### 2.2.2 Non-Persistent and Persistent Connections

  * HTTP connections
  * HTTP : default: persistent connection; runnable : both non-persistent and persistent
    * Non-persistent connection=>each request sent over a *separate* TCP connection
      * steps
        * client initialize connection, 2 sockets(1 client 1 server) established
        * client sends an request message to the server via its socket which include the path name
        * Server process receives the request message via its socket, retrieves the object, *encapsulates* the object in an HTTP response message, and sent back the message via its socket
        * HTTP server process tells TCP to close the TCP connection (TCP doesn't acctually close until it knows client has received the information)
        * client receive the object (HTML) and ask for reference object
        * repeat the steps above until get all the objects (parallel TCP connections are allowed)
      * at most one object sent over a TCP connection
        * The connection is then closed
      * downloading multiple objects required multiple connections
        * If we do not consider the transmission time, it takes two round trip time (i.e. **from client to server then back to client**) (RTT) to get each object (one for object, one for close TCP link request)
        * HTML : 2 RTT(for connection and request) +transmission of the HTML file Object : 2 RTT
    * Persist HTTP : Multiple objects can be sent over a single TCP connection between client and server
      * without pipelining
        * Client issues new request only when the previous one has been received
        * HTML : 2 RTT Each Object : 1 RTT
      * with pipelining
        * Multiple Web pages residing on the same server can be sent from the server to the same client over a single persistent TCP connection
        * Client issues new request as soon as it encounters a reference object
        * As little as 1 RTT for all the referenced objects (send all objects at the same time)

### 2.2.3 HTTP Message Format

* Two types of message : request messages and response messages
* HTTP Headers
  - General header
  - Request/Response header
* Request message (five lines)
  * The first line : **request line** => 3 fields
    * method field
    * URL field
    * HTTP version field
  * 2th : **header line**
    * specifies the host on which the object resides
    * As there is already a connection with TCP (i.e. already found the server), it is used for web cache
  * 3th : ```Connection:close``` : tell the server close the connection after sending the requested object
  * 4th : ```User-agent:``` : header line specifies the user agent, that is, the browser type that is making the request
  * 5th : ```Accept-language``` : just one of many content negotiation headers available in HTTP (use what kind of language, if it is not provided by the server, use the default language)
* HTTP Response message
  - Status-line (The first line)
    - HTTP version number 
    - Status code (indicating success or failure) (200 OK, 404 Not Found)
    - Status phrase (OK, Not Found)
  - General/Response/Entity Header (s)
    - Date
    - Last-Modified
    - Entity headers (propoty of enetity)
      - Content-Length
      - Content-Type
    - Entity body : Object itself

* Cookies

  * Allow sites to keep track of users
  * small chunck of data generated by Web server and stored on computer's hard disk
  * Fix problems caused by HTTP's stateless(server doesn't remember the information of client) protocol
  * Components:
    * a cookie header line in the HTTP response message
    * a cookie header line in the HTTP request message
    * a cookie file kept on the user's end system and managed by the user's browser
    * a back-end database at the Web site
  * Steps
    * First time of connect : 
      * When request comes in to serverm server creates a unique identification number and **creates an entry**(the cookie file) in its back-end database that is indexed by the identification number. Response message includes a ```Set-cookie:```header, which contains the number
      * when browser receives the HTTP response message, it sees the ```Set-cookie:``` header. Then browser appends a line(include the hostname of the server and the identification number in the header) to the special cookie file that it manages
    * After that
      * Every time browser request, it will consults her cookie file, and add the identification number in HTTP request
      * If client has sign up an account on the Web, thus the database has client's information, then everytime it will check the identification number with the database, user don't have to input the account and password again

* Web cache

  * Goal: statisfy client requests without involving the origin server

  * save the data at proxy server (distributed around the world) , cliet get the data from the closest server

  * User sets browser: Web accesses via cache (i.e. TCP connection to the Web cache)

  * Browser sends all HTTP requests to cache

    * object in the cache: the cache returns object 
    * Otherwise the cache requests the object from the origin server, then returns the object to the client and store the object into the Web cache's local storage

  * If origin updated (The conditional GET)

    * Goal : vdon’t send the object if cache has up-to-date cached version 

      - no object transmission delay (less than the delays)
      - lower link utilization

    * Request message uses the GET method and includes an ```If-Modified-Since``` : header line

    * when proxy server(cache) receive request it will check with origin server(just 版本号)

      ```
      If-modified-since : Wed, 19 Sep 2018 04:09:30	//Date
      ```

    * cache: specify date of cached copy in HTTP request 

    * server: response contains no object if cached copy is up-to-date:  ```304 Not Modified``` 

### 2.5 DNS - The Internet's Directory Service

* DNS : domain name system

  * IP address (32 bit) - used for addressing datagrams
  * domain name( **hostname**) => used by human

  * DNS : Directory service that **translates** hostnames to IP addresses => **domain name system**
    * property
      * distributed database implemented in hierarchy of many **DNS servers** (often **UNIX** machines ): to avoid attack(if it is save in a single one, will be attacked) => block chain to avoid attack
      * Application-layer protocol: hosts and name servers communicate to resolve names (address/name translation) 

### 2.5.2 Overview of How DNS Works

* Structure

  * If there is only one DNS server

    * A single point of failure
    * Traffic volume
    * Distant centralized database
    * Maintenance (DNS server has to keep records for all Internet hosts)

  * As a result => use distributed, hierarchical database

    * **Root DNS servers** : In the Internet there are 13 root DNS servers(labeled A through M) in the world 
    * **Top-level domain (TLD) servers** : These servers are responsible for top-level domains such as com, org, net, edu, and gov
    * **Authoritative DNS servers** : Every organization with publicly accessible hosts (such as Web servers and mail servers) on the Internet must provide publicly accessible DNS records that map the names pf those hosts to IP addresses (server can be rent or maintain one server yourself)

    ![](hierarchy.png)


- Process : client wants IP for www.amazon.com; (All DNS in the client use UDP transport protocol)

  - DNS client queries root server to find com DNS server 
  - client queries .com DNS server to get amazon.com DNS server
  - client queries amazon.com DNS server to get  IP address for www.amazon.com (it is a web server www rather than an e-mail server)

- Root DNS servers:

  - contacted by local name server that can not resolve name : nearest

  - root name server(向导):

    - contacts authoritative name server if name mapping not known
    - gets mapping
    - returns mapping to local name server

  - Local DNS name server

    - not the hierarchy but it is the one who send the query (beween DNS client and the **DNS Hierarchy**)

    - each ISP(Internet Service Provider) has one

    - when host makes DNS query, query is sent to its local DNS server 

    - has local cache of recent name-to-address translation pairs (but may be out of date!)

    - acts as proxy, forwards query into hierarchy

      ![](LocalDNS.png)

    - Iterated query: (the picture above 1&8 is recufsive query, others are Iterated query)

      - contacted server replies with name of server to contact
      - “I don’t know this name, but ask this server”
      - Cons : local DNS server will not benefit for others

    - recursive query:

      - deep first search
      - heavy load at upper levels of hierarchy

      ![](recursiveQuery.png)

### 2.6 Peer-to-Peer Applications

### 2.6.1 P2P File Distribution

* Scalability of P2P Architectures

  * Denotes

    * Denote upload rate of the server's access link by $u_s$
    * Denote upload rate of $ith$ peer's access link by $u_i$
    * Denote download rate of the $ith$ peer's access link by $d_i$
    * Denote the size of the file to be distributed (in bits) by $F$ and the number of peers that want to obtain a copy of the file by $N$
    * **Distribution time**: time it takes to get a copy of the file to all $N$ peers

  * Assumption

    * Internet core has abundant bandwidth => all of the bottlenecks are in access networks
    * Server and clients are not participating in any other network applications => all bandwidth used to distributing this file

  * Distribution time : $D_{cs}$

    * For Client-Server

      * The server must transmit one copy of the file to each of N peers => total $NF$ bits => rate = $NF \over u_s$
      * $d_{min}=min(d_1,d_2,...,d_N)$ The peer obtain all $F$ bits of the file in less than $F\over d_{min}$ seconds

      $$
      D_{cs} \geq max\{{NF\over u_s},{F\over d_{min}}\}
      $$

      * We take the lower bound (i.e. the equal case , best case)
      * The formular increasing linearly (with respect to N)

    * For P2P architecture

      * When a peer receives some file data, it can use its own upload capacity to redistribute the data to other peers => distribution time depends on how each peer distributes portions of the file to the other peers

      * Server need to send each bit of the file at least once into its access link (only server has the file at first) => minimum distribution time is at least $F/u_s$

      * The peer with the lowest download rate cannot obtain all $F$ bits of the file in less than $F/d_{min}$ seconds => minimum $F\over d_{min}$

      * Total upload capacity of the system as a whole is equal to the upload rate of the server plus the upload rates of each of the individual peers $u_{total}=u_s+u_1+...+u_N$ (every one contributes to get the largest rate). And the total file size is $NF$, thus the minimum time is $NF\over u_{total}$ .
        $$
        D_{cs}=max\{ {F \over u_s},{F \over d_{min}},{NF\over u_s+\sum^N_{i=1}u_i}\}
        $$

      * In reality, where chunks of the file are redistributed rather than individual bits, the equation is a good approximation

    * Set $F/u=1\ hour,\ u_s=10u,\ and\ d_{min} \geq u_s$ 

      ![](p2pFast.png)

- Pure P2P architecture
  - file divided into 256Kb chucks
  - peers in torrent send/receive file chunks
  - server just tell you who has what, and people change with each other
  - **tracker** : tracks peers participating in torrent (provide a list to client)
  - **torrent**: ==group== of peers exchanging chunks of a file
    - each torrent has a infrastructure node called a *tracker*
- P2P file distribution
  - BitTorrent ： In BitTorrent lingo(行话), the collection of all peers participating in the distribution of a particular file is called a *torrent* (include the whole group)
    - peers in a torrent download equal-size *chunks*(256KB) of the file from another
    - peer joining torrent
      - has no chunks, but will accumulate them over time from other peers
      - registers with tracker to get list of peers (tracker **randomly** selects a subset of peers, and send IP address to request peer), connects to subset of peers (“neighbors”)
    - requesting chunks
      - Ask neighbors for the list of chunks they have (By TCP connections)
      - Alice requests missing chunks from peers, **rarest first**, because no one always online => as a result equalize the copies of the different chunks
    - Sending chunks: tit-for-tat
      - sends to those top four peers (**unchoked**) currently send you *at highest rate* (re-evaluate 4 every 10 secs ) 
      - every 30 secs : randomly select another peer (**optimistically unchoked**), starts sending chunks (for the case of new client who didn't serve others) 

-------------------

## Transport layer

------

* Transport protocols
  * sender side: breaks app messages into segments, passes to  network layer
  * receiver side: reassembles segments into messages, passes to app layer
* Multiplexing/demultiplexing 
  * Multiplexing at sender : break data to segment, add transport header
  * demultiplexing at receiver : use header info to deliver received seemnts to correct socket (UDP use less information to demultiplexing)
  * Use 2 number to generate socket => maybe two different client ask for the same port in server (connectionless)
  * four numbers to spercify the process (source IP, source port, dest IP, dest port) (connection oriented)
  * Threaded(线程) server : in the same port, generate child API to deal with request of different client (main process generate new socket generate new thread process and combine them)
* 